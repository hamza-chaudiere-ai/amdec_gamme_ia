#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
G√©n√©rateur d'analyses AMDEC - VERSION REGROUPEMENT COMPOSANT+SOUS-COMPOSANT
‚úÖ REGROUPEMENT INTELLIGENT: Une seule ligne par composant+sous-composant
‚úÖ FUSION DES CAUSES: Concat√©nation de toutes les causes diff√©rentes
‚úÖ CALCUL GLOBAL: Fr√©quence bas√©e sur le nombre total d'occurrences
‚úÖ MODES FUSIONN√âS: Combination intelligente des modes de d√©faillance
"""

import pandas as pd
import numpy as np
import os
import logging
import re
from datetime import datetime
from typing import Dict, List, Optional, Union, Tuple
import openpyxl
from openpyxl.styles import Font, Alignment, PatternFill, Border, Side

from .utils import (
    format_component_display,
    format_subcomponent_display,
    calculate_criticality,
    get_criticality_color,
    generate_timestamp,
    ComponentConfig
)

logger = logging.getLogger(__name__)

class AMDECGenerator:
    """
    ‚úÖ G√âN√âRATEUR AMDEC avec REGROUPEMENT par COMPOSANT+SOUS-COMPOSANT
    
    Fonctionnalit√©s sp√©ciales :
    - Regroupement unique par composant + sous-composant (ignorer causes)
    - Fusion intelligente des causes multiples
    - Calcul de fr√©quence globale selon grille officielle
    - Concat√©nation des modes de d√©faillance
    """
    
    def __init__(self, data: Optional[pd.DataFrame] = None):
        """
        Initialise le g√©n√©rateur AMDEC avec regroupement intelligent
        
        Args:
            data: DataFrame avec donn√©es d'historique (optionnel)
        """
        self.data = data
        self.original_data = None
        self.amdec_data = []
        self.amdec_df = None
        self.output_path = None
        self.grouping_stats = {}
        
        # Chargement des mod√®les de r√©f√©rence
        self.reference_models = self._load_reference_models()
        
        # Base de connaissances pour la g√©n√©ration intelligente
        self.knowledge_base = self._build_knowledge_base()
    
    def generate(self) -> pd.DataFrame:
        """
        ‚úÖ G√âN√âRATION AMDEC avec REGROUPEMENT COMPOSANT+SOUS-COMPOSANT
        """
        try:
            logger.info("üîÑ D√©but g√©n√©ration AMDEC avec regroupement composant+sous-composant")
            
            if self.data is not None and not self.data.empty:
                # ‚úÖ TRAITEMENT avec regroupement par composant+sous-composant
                self._process_historical_data_with_component_grouping()
            else:
                # G√©n√©ration √† partir des mod√®les de r√©f√©rence
                self._generate_from_models()
            
            # Post-traitement et optimisation
            self._optimize_amdec()
            
            # ‚úÖ Cr√©ation DataFrame PROPRE (sans colonnes suppl√©mentaires)
            self._create_clean_dataframe()
            
            logger.info(f"‚úÖ AMDEC g√©n√©r√©e: {len(self.amdec_data)} entr√©es consolid√©es par composant+sous-composant")
            return self.amdec_df
            
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de la g√©n√©ration AMDEC: {e}")
            raise
    
    def _process_historical_data_with_component_grouping(self):
        """
        ‚úÖ TRAITEMENT SP√âCIAL avec regroupement par COMPOSANT+SOUS-COMPOSANT uniquement
        
        Pipeline :
        1. Validation des donn√©es d'entr√©e
        2. Regroupement par (composant, sous_composant) SEULEMENT
        3. Fusion de toutes les causes pour chaque groupe
        4. Calcul de fr√©quence globale selon grille officielle
        5. G√©n√©ration des entr√©es AMDEC consolid√©es
        """
        logger.info("üîÑ Traitement avec regroupement COMPOSANT+SOUS-COMPOSANT")
        
        # Sauvegarder les donn√©es originales
        self.original_data = self.data.copy()
        
        # ‚úÖ √âTAPE 1: Validation des donn√©es d'entr√©e
        required_columns = ['composant', 'sous_composant']
        missing_columns = [col for col in required_columns if col not in self.data.columns]
        
        if missing_columns:
            raise ValueError(f"‚ùå Colonnes manquantes pour regroupement: {missing_columns}")
        
        # S'assurer que les colonnes optionnelles existent
        if 'cause' not in self.data.columns:
            self.data['cause'] = 'non_specifie'
        if 'duree' not in self.data.columns:
            self.data['duree'] = 1.0
        
        logger.info(f"üìä Donn√©es d'entr√©e: {len(self.data)} lignes")
        
        # ‚úÖ √âTAPE 2: Regroupement EXCLUSIVEMENT par composant+sous-composant
        self._perform_component_subcomponent_grouping()
        
        logger.info(f"‚úÖ Regroupement termin√©: {len(self.amdec_data)} entr√©es AMDEC uniques")
    
    def _perform_component_subcomponent_grouping(self):
        """
        ‚úÖ REGROUPEMENT PRINCIPAL par COMPOSANT+SOUS-COMPOSANT uniquement
        
        Toutes les causes diff√©rentes sont fusionn√©es pour un m√™me composant+sous-composant
        """
        logger.info("üìä Regroupement par COMPOSANT + SOUS-COMPOSANT...")
        
        # ‚úÖ Regroupement sur SEULEMENT (composant, sous-composant)
        grouping_cols = ['composant', 'sous_composant']
        
        logger.info(f"üìä Regroupement sur: {grouping_cols}")
        logger.info(f"üìä Donn√©es avant regroupement: {len(self.data)} lignes")
        
        # Effectuer le regroupement avec agr√©gations intelligentes
        try:
            grouped = self.data.groupby(grouping_cols, dropna=False).agg({
                'cause': lambda x: list(x),  # Toutes les causes
                'duree': ['count', 'mean', 'sum', 'max', 'min'],  # Statistiques dur√©es
                'date_arret': 'count' if 'date_arret' in self.data.columns else lambda x: len(x),
                'line_id': 'count' if 'line_id' in self.data.columns else lambda x: len(x)
            }).reset_index()
            
            # Aplatir les colonnes multi-niveaux
            grouped.columns = [
                'composant', 'sous_composant',
                'causes_list', 
                'nb_occurrences', 'duree_moyenne', 'duree_totale', 'duree_max', 'duree_min',
                'date_count', 'line_count'
            ]
            
        except Exception as e:
            logger.error(f"‚ùå Erreur regroupement: {e}")
            grouped = self._fallback_simple_grouping()
        
        logger.info(f"üìä Regroupement effectu√©: {len(self.data)} lignes ‚Üí {len(grouped)} groupes uniques")
        
        # ‚úÖ √âTAPE 3: Traiter chaque groupe et cr√©er entr√©e AMDEC
        for _, group in grouped.iterrows():
            try:
                self._create_amdec_entry_from_group(group)
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Erreur traitement groupe: {e}")
                continue
        
        # Statistiques de regroupement
        self.grouping_stats = {
            'original_lines': len(self.data),
            'grouped_entries': len(grouped),
            'amdec_entries_created': len(self.amdec_data),
            'compression_ratio': len(grouped) / len(self.data) if len(self.data) > 0 else 0
        }
        
        logger.info(f"üìä Statistiques regroupement: {len(self.data)} ‚Üí {len(grouped)} groupes ‚Üí {len(self.amdec_data)} AMDEC")
    
    def _create_amdec_entry_from_group(self, group_data: pd.Series):
        """
        ‚úÖ CR√âATION d'une entr√©e AMDEC √† partir d'un groupe consolid√©
        
        Args:
            group_data: Donn√©es du groupe (composant+sous-composant avec toutes ses causes)
        """
        try:
            component = str(group_data['composant'])
            subcomponent = str(group_data['sous_composant'])
            
            # Valider les donn√©es de base
            if any(val in ['nan', 'None', ''] for val in [component, subcomponent]):
                logger.debug(f"‚ö†Ô∏è Donn√©es incompl√®tes ignor√©es: {component}-{subcomponent}")
                return
            
            # ‚úÖ TRAITEMENT des causes multiples
            causes_list = group_data['causes_list']
            if isinstance(causes_list, list):
                unique_causes = list(set([str(c) for c in causes_list if str(c) not in ['nan', 'None', 'non_specifie']]))
            else:
                unique_causes = [str(causes_list)]
            
            # Supprimer les causes vides
            unique_causes = [c for c in unique_causes if c.strip() != '']
            if not unique_causes:
                unique_causes = ['non_specifie']
            
            # ‚úÖ FUSION INTELLIGENTE des causes
            if len(unique_causes) == 1:
                consolidated_cause = unique_causes[0]
            elif len(unique_causes) <= 3:
                consolidated_cause = ' + '.join(unique_causes)
            else:
                # Si trop de causes, prendre les 3 principales + "autres"
                main_causes = unique_causes[:3]
                consolidated_cause = ' + '.join(main_causes) + f' (+{len(unique_causes)-3} autres)'
            
            # ‚úÖ CALCUL de la fr√©quence OFFICIELLE selon grille
            nb_occurrences = int(group_data['nb_occurrences'])
            frequency = self._calculate_frequency_OFFICIAL_GRID(nb_occurrences)
            
            # ‚úÖ CALCUL de la gravit√© am√©lior√©e
            if pd.notna(group_data['duree_moyenne']):
                duree_moyenne = float(group_data['duree_moyenne'])
                duree_max = float(group_data.get('duree_max', duree_moyenne))
                gravity = self._calculate_gravity_ENHANCED(duree_moyenne, duree_max, nb_occurrences)
            else:
                gravity = self._estimate_gravity_from_causes(unique_causes)
            
            # ‚úÖ CALCUL de la d√©tection intelligente
            detection = self._calculate_detection_from_causes_SMART(unique_causes)
            
            # ‚úÖ Criticit√© = F √ó G √ó D
            criticality = calculate_criticality(frequency, gravity, detection)
            
            # ‚úÖ G√âN√âRATION des autres attributs intelligents
            failure_modes = self._determine_failure_modes_MULTIPLE(unique_causes, subcomponent, nb_occurrences)
            consolidated_failure_mode = self._consolidate_failure_modes(failure_modes)
            
            effect = self._determine_effect_COMPREHENSIVE(consolidated_failure_mode, gravity, nb_occurrences, len(unique_causes))
            function = self._determine_function_ENHANCED(component, subcomponent)
            actions = self._generate_corrective_actions_COMPREHENSIVE(unique_causes, criticality, nb_occurrences)
            
            # ‚úÖ CR√âER l'entr√©e AMDEC FINALE
            entry = {
                'Composant': format_component_display(component),
                'Sous-composant': format_subcomponent_display(subcomponent),
                'Fonction': function,
                'Mode de D√©faillance': consolidated_failure_mode,
                'Cause': consolidated_cause,
                'Effet': effect,
                'F': frequency,  # ‚úÖ Fr√©quence selon GRILLE OFFICIELLE
                'G': gravity,
                'D': detection,
                'C': criticality,  # ‚úÖ Criticit√© recalcul√©e OFFICIELLEMENT
                'Actions Correctives': actions
            }
            
            self.amdec_data.append(entry)
            
            logger.debug(f"‚úÖ Entr√©e AMDEC cr√©√©e: {component}-{subcomponent} ‚Üí C={criticality} (F={frequency} pour {nb_occurrences} occurrences, {len(unique_causes)} causes)")
            
        except Exception as e:
            logger.error(f"‚ùå Erreur cr√©ation entr√©e AMDEC: {e}")
    
    def _calculate_frequency_OFFICIAL_GRID(self, nb_occurrences: int) -> int:
        """
        ‚úÖ GRILLE OFFICIELLE: Calcul EXACT de la fr√©quence selon grille demand√©e
        
        GRILLE OFFICIELLE:
        - 1 occurrence = F=1 (Tr√®s faible - rare, <1/an)
        - 2 √† 3 occurrences = F=2 (Faible - possible, <1/trimestre)
        - 4 √† 7 occurrences = F=3 (Moyenne - fr√©quente, <1/semaine)
        - 8+ occurrences = F=4 (Forte - plusieurs fois/semaine)
        
        Args:
            nb_occurrences: Nombre TOTAL d'occurrences pour ce composant+sous-composant
            
        Returns:
            Fr√©quence F selon grille officielle
        """
        if nb_occurrences == 1:
            return 1  # Tr√®s faible
        elif 2 <= nb_occurrences <= 3:
            return 2  # Faible
        elif 4 <= nb_occurrences <= 7:
            return 3  # Moyenne
        else:  # 8 et plus
            return 4  # Forte
    
    def _calculate_gravity_ENHANCED(self, duree_moyenne: float, duree_max: float, nb_occurrences: int) -> int:
        """
        ‚úÖ CALCUL AM√âLIOR√â de la gravit√© G
        
        Args:
            duree_moyenne: Dur√©e moyenne des arr√™ts
            duree_max: Dur√©e maximale observ√©e
            nb_occurrences: Nombre d'occurrences
            
        Returns:
            Gravit√© G (1-5)
        """
        # Utiliser la dur√©e la plus repr√©sentative selon le nombre d'occurrences
        if nb_occurrences >= 5:
            duree_reference = duree_moyenne  # Moyenne fiable
        elif nb_occurrences >= 3:
            duree_reference = (duree_moyenne + duree_max) / 2  # Mix moyenne/max
        else:
            duree_reference = duree_max  # Prendre le pire cas
        
        # Ajustement selon la r√©currence (plus d'occurrences = impact plus grave)
        if nb_occurrences >= 8:
            duree_reference *= 1.3  # Aggravation significative
        elif nb_occurrences >= 5:
            duree_reference *= 1.1  # Aggravation mod√©r√©e
        
        # Bar√®me de gravit√© industriel (en heures)
        if duree_reference < 0.5:
            return 1  # N√©gligeable (< 30 min)
        elif duree_reference < 2:
            return 2  # Mineure (< 2h)
        elif duree_reference < 8:
            return 3  # Mod√©r√©e (< 8h)
        elif duree_reference < 24:
            return 4  # Majeure (< 1 jour)
        else:
            return 5  # Catastrophique (> 1 jour)
    
    def _estimate_gravity_from_causes(self, causes: List[str]) -> int:
        """
        ‚úÖ ESTIMATION de gravit√© bas√©e sur les types de causes
        
        Args:
            causes: Liste des causes uniques
            
        Returns:
            Gravit√© estim√©e (1-5)
        """
        max_gravity = 2  # Gravit√© de base
        
        # Mapping des gravit√©s par type de cause
        gravity_mapping = {
            'surchauffe': 4,     # Grave car peut causer rupture
            'fissure': 4,        # Grave car peut √©voluer vers rupture
            'rupture': 5,        # Catastrophique
            'explosion': 5,      # Catastrophique
            'percement': 4,      # Grave
            'corrosion': 3,      # Mod√©r√©e mais progressive
            'erosion': 3,        # Mod√©r√©e mais progressive
            'fatigue': 3,        # Mod√©r√©e mais r√©p√©titive
            'usure': 2,          # Mineure si d√©tect√©e t√¥t
            'encrassement': 2,   # Mineure, r√©versible
            'vibration': 2,      # Mineure mais peut √©voluer
            'fuite': 3           # Mod√©r√©e selon l'ampleur
        }
        
        # Prendre la gravit√© maximale parmi toutes les causes
        for cause in causes:
            cause_lower = cause.lower()
            for cause_key, gravity in gravity_mapping.items():
                if cause_key in cause_lower:
                    max_gravity = max(max_gravity, gravity)
        
        # Bonus si multiples causes (combinaison = plus grave)
        if len(causes) >= 3:
            max_gravity = min(max_gravity + 1, 5)
        
        return max_gravity
    
    def _calculate_detection_from_causes_SMART(self, causes: List[str]) -> int:
        """
        ‚úÖ CALCUL INTELLIGENT de la d√©tection D bas√© sur TOUTES les causes
        
        Args:
            causes: Liste des causes uniques
            
        Returns:
            D√©tection D (1-4) - Prend la MEILLEURE d√©tection (plus facile)
        """
        min_detection = 4  # Commencer par le pire (tr√®s difficile)
        
        detection_mapping = {
            # Tr√®s facile √† d√©tecter (D=1)
            'fuite': 1, 'percement': 1, 'rupture': 1, 'explosion': 1, 'surchauffe': 1,
            'vibration': 1, 'bruit': 1, 'temperature': 1, 'alerte': 1,
            
            # Facile √† d√©tecter (D=2)
            'corrosion': 2, 'erosion': 2, 'encrassement': 2, 'obstruction': 2,
            'deformation': 2, 'usure': 2, 'rouille': 2,
            
            # Difficile √† d√©tecter (D=3)
            'fissure': 3, 'fatigue': 3, 'microfissure': 3, 'contrainte': 3,
            'dilatation': 3, 'fluage': 3,
            
            # Tr√®s difficile √† d√©tecter (D=4)
            'defaut_interne': 4, 'vieillissement': 4, 'degradation_lente': 4,
            'contamination': 4, 'impurete': 4, 'non_specifie': 4
        }
        
        # Prendre la MEILLEURE d√©tection (plus facile = valeur plus faible)
        for cause in causes:
            cause_lower = cause.lower()
            for cause_key, detection_value in detection_mapping.items():
                if cause_key in cause_lower:
                    min_detection = min(min_detection, detection_value)
        
        return min_detection
    
    def _determine_failure_modes_MULTIPLE(self, causes: List[str], subcomponent: str, nb_occurrences: int) -> List[str]:
        """
        ‚úÖ D√âTERMINATION de modes de d√©faillance MULTIPLES
        
        Args:
            causes: Liste des causes
            subcomponent: Sous-composant
            nb_occurrences: Nombre d'occurrences
            
        Returns:
            Liste des modes de d√©faillance
        """
        modes = []
        subcomp_lower = subcomponent.lower()
        
        smart_mapping = {
            'corrosion': {
                'epingle': 'Corrosion externe g√©n√©ralis√©e',
                'collecteur': 'Corrosion interne par chimie eau',
                'tube': 'Corrosion c√¥t√© feu/fum√©es',
                'branches': 'Corrosion sous contrainte',
                'default': 'Corrosion progressive'
            },
            'erosion': {
                'epingle': '√ârosion par cendres volantes',
                'collecteur': '√ârosion par circulation fluide',
                'tube': '√ârosion par particules en suspension',
                'branches': '√ârosion par vitesse excessive',
                'default': '√ârosion m√©canique'
            },
            'fissure': {
                'epingle': 'Fissuration thermique cyclique',
                'collecteur': 'Fissures intergranulaires',
                'tube': 'Fatigue thermom√©canique',
                'branches': 'Fissuration par contrainte',
                'default': 'Fissuration progressive'
            },
            'fatigue': {
                'epingle': 'Fatigue thermique cyclique',
                'collecteur': 'Fatigue m√©canique',
                'tube': 'Fatigue par cycles pression',
                'branches': 'Fatigue vibratoire',
                'default': 'Fatigue cyclique'
            },
            'surchauffe': {
                'epingle': 'Surchauffe locale critique',
                'collecteur': 'Surchauffe par stagnation',
                'tube': 'Surchauffe long terme (fluage)',
                'branches': 'Surchauffe par d√©s√©quilibre',
                'default': 'Surchauffe op√©rationnelle'
            }
        }
        
        # D√©terminer le type de sous-composant
        comp_type = 'default'
        for key in ['epingle', 'collecteur', 'tube', 'branches']:
            if key in subcomp_lower:
                comp_type = key
                break
        
        # G√©n√©rer un mode pour chaque cause
        for cause in causes:
            cause_lower = cause.lower()
            mode_found = False
            
            for cause_key, modes_dict in smart_mapping.items():
                if cause_key in cause_lower:
                    base_mode = modes_dict.get(comp_type, modes_dict['default'])
                    modes.append(base_mode)
                    mode_found = True
                    break
            
            if not mode_found:
                modes.append(f'D√©faillance par {cause}')
        
        return modes
    
    def _consolidate_failure_modes(self, modes: List[str]) -> str:
        """
        ‚úÖ CONSOLIDATION intelligente des modes de d√©faillance multiples
        
        Args:
            modes: Liste des modes de d√©faillance
            
        Returns:
            Mode consolid√©
        """
        if not modes:
            return 'Mode de d√©faillance non sp√©cifi√©'
        
        if len(modes) == 1:
            return modes[0]
        elif len(modes) <= 3:
            return ' + '.join(modes)
        else:
            # Si trop de modes, grouper par famille
            mode_families = {}
            for mode in modes:
                if 'corrosion' in mode.lower():
                    mode_families.setdefault('Corrosion', []).append(mode)
                elif 'fissure' in mode.lower() or 'fatigue' in mode.lower():
                    mode_families.setdefault('Fatigue/Fissuration', []).append(mode)
                elif 'erosion' in mode.lower() or 'usure' in mode.lower():
                    mode_families.setdefault('√ârosion/Usure', []).append(mode)
                elif 'surchauffe' in mode.lower():
                    mode_families.setdefault('Surchauffe', []).append(mode)
                else:
                    mode_families.setdefault('Autres', []).append(mode)
            
            if len(mode_families) <= 3:
                return ' + '.join(mode_families.keys())
            else:
                main_families = list(mode_families.keys())[:2]
                return ' + '.join(main_families) + f' (+{len(mode_families)-2} autres)'
    
    def _determine_effect_COMPREHENSIVE(self, failure_mode: str, gravity: int, nb_occurrences: int, nb_causes: int) -> str:
        """
        ‚úÖ EFFET COMPLET bas√© sur mode, gravit√©, r√©currence ET multiplicit√© des causes
        
        Args:
            failure_mode: Mode de d√©faillance consolid√©
            gravity: Gravit√©
            nb_occurrences: Nombre d'occurrences
            nb_causes: Nombre de causes diff√©rentes
            
        Returns:
            Effet d√©taill√©
        """
        mode_lower = failure_mode.lower()
        
        # Effet de base selon le mode principal
        if 'corrosion' in mode_lower:
            if gravity <= 2:
                base_effect = 'Amincissement local des parois'
            elif gravity <= 3:
                base_effect = 'Perte de mati√®re significative'
            else:
                base_effect = 'Perforation et fuite majeure'
                
        elif 'fissure' in mode_lower or 'fatigue' in mode_lower:
            if gravity <= 2:
                base_effect = 'Microfissures superficielles'
            elif gravity <= 3:
                base_effect = 'Fissures traversantes locales'
            else:
                base_effect = 'Rupture catastrophique'
                
        elif 'erosion' in mode_lower:
            if gravity <= 2:
                base_effect = 'Usure superficielle progressive'
            elif gravity <= 3:
                base_effect = 'Amincissement acc√©l√©r√©'
            else:
                base_effect = 'Perforation par √©rosion'
                
        elif 'surchauffe' in mode_lower:
            if gravity <= 2:
                base_effect = 'D√©formation plastique mineure'
            elif gravity <= 3:
                base_effect = 'Fluage et d√©formation permanente'
            else:
                base_effect = 'Rupture ductile imm√©diate'
        else:
            if gravity <= 2:
                base_effect = 'Impact mineur sur performance'
            elif gravity <= 3:
                base_effect = 'D√©gradation notable performance'
            else:
                base_effect = 'Arr√™t impr√©vu et co√ªteux'
        
        # Ajouts selon la r√©currence
        if nb_occurrences >= 8:
            base_effect = f"{base_effect} + R√©currence CRITIQUE ({nb_occurrences} fois)"
        elif nb_occurrences >= 5:
            base_effect = f"{base_effect} + R√©currence pr√©occupante ({nb_occurrences} fois)"
        elif nb_occurrences >= 3:
            base_effect = f"{base_effect} + Tendance r√©p√©titive"
        
        # Ajouts selon la multiplicit√© des causes
        if nb_causes >= 4:
            base_effect = f"{base_effect} + D√©faillance MULTI-CAUSES ({nb_causes} causes)"
        elif nb_causes >= 2:
            base_effect = f"{base_effect} + Causes multiples"
        
        return base_effect
    
    def _determine_function_ENHANCED(self, component: str, subcomponent: str) -> str:
        """
        ‚úÖ FONCTION pr√©cise selon l'expertise industrielle
        
        Args:
            component: Composant
            subcomponent: Sous-composant
            
        Returns:
            Fonction d√©taill√©e
        """
        comp_lower = component.lower()
        subcomp_lower = subcomponent.lower()
        
        function_mapping = {
            'economiseur': {
                'epingle': 'R√©cup√©ration chaleur fum√©es ‚Üí pr√©chauffage eau alimentation',
                'collecteur_entree': 'Distribution eau alimentation vers nappes',
                'collecteur_sortie': 'Collecte eau pr√©chauff√©e vers ballon',
                'tubes_suspension': 'Support m√©canique + guidage dilatation thermique'
            },
            'surchauffeur': {
                'epingle': 'Surchauffe vapeur satur√©e ‚Üí vapeur haute temp√©rature service',
                'tube_porteur': 'R√©sistance pression service + transfert thermique optimal',
                'branches_entree': 'Distribution vapeur satur√©e vers nappes surchauffe',
                'branches_sortie': 'Collecte vapeur surchauff√©e vers collecteur principal',
                'collecteur_entree': 'Distribution vapeur satur√©e depuis ballon',
                'collecteur_sortie': 'Collecte vapeur surchauff√©e finale vers turbine'
            },
            'rechauffeur': {
                'collecteur_entree': 'Distribution vapeur partiellement d√©tendue',
                'collecteur_sortie': 'Collecte vapeur r√©chauff√©e vers turbine BP',
                'tubes_suspension': 'Support structural + r√©sistance cycles thermiques',
                'tube_porteur': 'Support m√©canique r√©sistant haute pression + temp√©rature',
                'branches_entree': 'Distribution vapeur vers √©changeur r√©chauffage',
                'branches_sortie': '√âvacuation vapeur r√©chauff√©e optimis√©e vers turbine'
            }
        }
        
        # Identifier le type de composant principal
        comp_type = None
        for key in ['economiseur', 'surchauffeur', 'rechauffeur']:
            if key in comp_lower:
                comp_type = key
                break
        
        if comp_type and comp_type in function_mapping:
            for subcomp_key, function in function_mapping[comp_type].items():
                if subcomp_key in subcomp_lower or any(part in subcomp_lower for part in subcomp_key.split('_')):
                    return function
        
        return 'Fonction de transfert thermique et r√©sistance m√©canique sous pression'
    
    def _generate_corrective_actions_COMPREHENSIVE(self, causes: List[str], criticality: int, nb_occurrences: int) -> str:
        """
        ‚úÖ ACTIONS CORRECTIVES COMPL√àTES pour causes multiples
        
        Args:
            causes: Liste des causes
            criticality: Criticit√©
            nb_occurrences: Nombre d'occurrences
            
        Returns:
            Actions correctives d√©taill√©es
        """
        # Base d'actions par cause
        actions_by_cause = {
            'corrosion': [
                'Analyse chimique eau/vapeur compl√®te',
                'Rev√™tement anticorrosion c√©ramique',
                'Injection inhibiteurs corrosion',
                'Contr√¥le pH automatis√© en continu'
            ],
            'erosion': [
                'Contr√¥le vitesse circulation optimis√©e',
                'Installation d√©flecteurs protection',
                'Rev√™tement dur anti-usure',
                'Am√©lioration filtration particules'
            ],
            'fissure': [
                'Inspection CND (PAUT) syst√©matique',
                'R√©paration soudage qualifi√© ASME',
                'Analyse contraintes √©l√©ments finis',
                'Modification supportage renforc√©'
            ],
            'fatigue': [
                'Surveillance vibratoire continue IoT',
                'Renforcement supports anti-vibratoire',
                'Analyse cycles contraintes d√©taill√©e',
                'Installation amortisseurs'
            ],
            'surchauffe': [
                'Optimisation r√©glages combustion',
                'Capteurs temp√©rature distribu√©s',
                'Am√©lioration refroidissement forc√©',
                'Alarmes haute temp√©rature pr√©coces'
            ]
        }
        
        # D√©terminer le niveau de maintenance selon criticit√© ET r√©currence
        if criticality <= 12 and nb_occurrences <= 2:
            maintenance_level = "Maintenance corrective planifi√©e"
            nb_actions = 1
        elif criticality <= 16 and nb_occurrences <= 3:
            maintenance_level = "Maintenance pr√©ventive syst√©matique"
            nb_actions = 2
        elif criticality <= 20 or nb_occurrences <= 5:
            maintenance_level = "Maintenance pr√©ventive conditionnelle renforc√©e"
            nb_actions = 3
        else:
            maintenance_level = "Remise en cause conception + surveillance critique"
            nb_actions = 4
        
        # Ajustement PRIORITAIRE selon la r√©currence ET multiplicit√©
        if nb_occurrences >= 8 or len(causes) >= 4:
            maintenance_level = "üî¥ URGENCE CRITIQUE: " + maintenance_level
            nb_actions = min(nb_actions + 2, 5)
        elif nb_occurrences >= 5 or len(causes) >= 3:
            maintenance_level = "üü† PRIORIT√â HAUTE: " + maintenance_level
            nb_actions = min(nb_actions + 1, 4)
        elif nb_occurrences >= 3 or len(causes) >= 2:
            maintenance_level = "üü° ATTENTION: " + maintenance_level
        
        # Collecter les actions pour toutes les causes
        all_actions = set()
        for cause in causes:
            cause_lower = cause.lower()
            for cause_key, actions in actions_by_cause.items():
                if cause_key in cause_lower:
                    all_actions.update(actions[:nb_actions])
                    break
        
        # Actions par d√©faut si aucune correspondance
        if not all_actions:
            all_actions = {
                'Surveillance renforc√©e multi-param√®tres',
                'Analyse expertise sp√©cialis√©e approfondie',
                'Plan d\'actions correctives personnalis√©',
                'Formation personnel intervention sp√©cialis√©e'
            }
        
        # Limiter le nombre d'actions selon le niveau
        selected_actions = list(all_actions)[:nb_actions]
        
        # Composer le r√©sultat final
        result = maintenance_level + " + " + " + ".join(selected_actions)
        
        # Ajouter mention sp√©ciale pour causes multiples
        if len(causes) >= 3:
            result = f"{result} + APPROCHE GLOBALE pour {len(causes)} causes combin√©es"
        
        return result
    
    def _fallback_simple_grouping(self) -> pd.DataFrame:
        """
        ‚úÖ REGROUPEMENT DE SECOURS en cas d'erreur
        """
        logger.warning("‚ö†Ô∏è Utilisation du regroupement de secours...")
        
        groups = []
        seen_combinations = set()
        
        for _, row in self.data.iterrows():
            try:
                # Cr√©er une cl√© de regroupement (composant + sous-composant seulement)
                key = (
                    str(row.get('composant', '')).lower().strip(),
                    str(row.get('sous_composant', '')).lower().strip()
                )
                
                if key not in seen_combinations:
                    seen_combinations.add(key)
                    
                    # Trouver toutes les lignes avec cette combinaison
                    mask = (
                        (self.data['composant'].astype(str).str.lower().str.strip() == key[0]) &
                        (self.data['sous_composant'].astype(str).str.lower().str.strip() == key[1])
                    )
                    
                    subset = self.data[mask]
                    
                    # Collecter toutes les causes
                    causes_list = subset['cause'].dropna().astype(str).tolist()
                    
                    group_data = {
                        'composant': row['composant'],
                        'sous_composant': row['sous_composant'],
                        'causes_list': causes_list,
                        'nb_occurrences': len(subset),
                        'duree_moyenne': subset['duree'].mean() if 'duree' in subset.columns else 1.0,
                        'duree_max': subset['duree'].max() if 'duree' in subset.columns else 1.0,
                        'duree_min': subset['duree'].min() if 'duree' in subset.columns else 1.0,
                        'duree_totale': subset['duree'].sum() if 'duree' in subset.columns else len(subset),
                        'date_count': len(subset),
                        'line_count': len(subset)
                    }
                    
                    groups.append(group_data)
                    
            except Exception as e:
                logger.debug(f"Erreur traitement ligne regroupement secours: {e}")
                continue
        
        return pd.DataFrame(groups)
    
    # ===============================
    # M√âTHODES CONSERV√âES UTILITAIRES
    # ===============================
    
    def save_dataset_amdec(self, amdec_data: List[Dict], component: str, subcomponent: str = None) -> str:
        """‚úÖ Sauvegarde l'AMDEC g√©n√©r√©e depuis le dataset"""
        try:
            self.amdec_df = pd.DataFrame(amdec_data)
            
            if self.amdec_df.empty:
                raise ValueError("Aucune donn√©e AMDEC √† sauvegarder")
            
            self._clean_dataframe_for_export()
            
            output_dir = 'data/generated/amdec'
            os.makedirs(output_dir, exist_ok=True)
            
            timestamp = generate_timestamp()
            safe_component = component.lower().replace(' ', '_')
            if subcomponent:
                safe_subcomponent = subcomponent.lower().replace(' ', '_')
                filename = f"amdec_dataset_{safe_component}_{safe_subcomponent}_{timestamp}.xlsx"
            else:
                filename = f"amdec_dataset_{safe_component}_{timestamp}.xlsx"
            
            output_path = os.path.join(output_dir, filename)
            self._save_formatted_excel_CLEAN(output_path)
            
            self.output_path = output_path
            logger.info(f"‚úÖ AMDEC dataset sauvegard√©e: {output_path}")
            
            return output_path
            
        except Exception as e:
            logger.error(f"‚ùå Erreur sauvegarde AMDEC dataset: {e}")
            raise
    
    def generate_gammes_from_amdec(self, amdec_file_path: str = None) -> List[str]:
        """‚úÖ G√©n√®re automatiquement les gammes depuis l'AMDEC avec images"""
        try:
            from .gamme_generator import GammeGenerator
            
            if amdec_file_path is None:
                if self.output_path is None:
                    raise ValueError("Aucun fichier AMDEC disponible")
                amdec_file_path = self.output_path
            
            if not os.path.exists(amdec_file_path):
                raise FileNotFoundError(f"Fichier AMDEC non trouv√©: {amdec_file_path}")
            
            df_amdec = pd.read_excel(amdec_file_path)
            gamme_generator = GammeGenerator()
            generated_gammes = []
            
            for _, row in df_amdec.iterrows():
                try:
                    component = row['Composant'].lower().replace(' ', '_')
                    subcomponent = row['Sous-composant'].lower().replace(' ', '_')
                    criticality = int(row['C'])
                    
                    logger.info(f"üîÑ G√©n√©ration gamme pour {component}-{subcomponent} (C={criticality})")
                    
                    gamme_data = gamme_generator.generate(component, subcomponent, criticality)
                    
                    # Enrichir avec informations AMDEC
                    gamme_data['amdec_cause'] = row['Cause']
                    gamme_data['amdec_mode'] = row['Mode de D√©faillance']
                    gamme_data['amdec_actions'] = row['Actions Correctives']
                    gamme_data['amdec_effect'] = row.get('Effet', 'Non sp√©cifi√©')
                    gamme_data['amdec_function'] = row.get('Fonction', 'Non sp√©cifi√©')
                    
                    output_path = gamme_generator.save_to_file(gamme_data, component, subcomponent)
                    generated_gammes.append(output_path)
                    
                    logger.info(f"‚úÖ Gamme cr√©√©e: {os.path.basename(output_path)}")
                    
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Erreur g√©n√©ration gamme: {e}")
                    continue
            
            logger.info(f"‚úÖ {len(generated_gammes)} gammes g√©n√©r√©es automatiquement")
            return generated_gammes
            
        except Exception as e:
            logger.error(f"‚ùå Erreur g√©n√©ration gammes: {e}")
            raise
    
    def _clean_dataframe_for_export(self):
        """‚úÖ Nettoie le DataFrame pour export (colonnes standard uniquement)"""
        standard_columns = [
            'Composant', 'Sous-composant', 'Fonction', 'Mode de D√©faillance',
            'Cause', 'Effet', 'F', 'G', 'D', 'C', 'Actions Correctives'
        ]
        
        if not self.amdec_df.empty:
            available_columns = [col for col in standard_columns if col in self.amdec_df.columns]
            self.amdec_df = self.amdec_df[available_columns]
            logger.info(f"‚úÖ DataFrame nettoy√©: {len(available_columns)} colonnes standard")
    
    def _create_clean_dataframe(self):
        """‚úÖ Cr√©e le DataFrame final propre"""
        if not self.amdec_data:
            standard_columns = [
                'Composant', 'Sous-composant', 'Fonction', 'Mode de D√©faillance',
                'Cause', 'Effet', 'F', 'G', 'D', 'C', 'Actions Correctives'
            ]
            self.amdec_df = pd.DataFrame(columns=standard_columns)
        else:
            self.amdec_df = pd.DataFrame(self.amdec_data)
            self._clean_dataframe_for_export()
            
            if not self.amdec_df.empty:
                self.amdec_df = self.amdec_df.sort_values(
                    ['Composant', 'C'], 
                    ascending=[True, False]
                ).reset_index(drop=True)
        
        logger.info(f"‚úÖ DataFrame PROPRE cr√©√©: {len(self.amdec_df)} entr√©es consolid√©es")
    
    def _save_formatted_excel_CLEAN(self, output_path: str):
        """‚úÖ Sauvegarde Excel format√© proprement"""
        self._clean_dataframe_for_export()
        self.amdec_df.to_excel(output_path, index=False)
        
        try:
            wb = openpyxl.load_workbook(output_path)
            ws = wb.active
            
            # Styles
            header_font = Font(bold=True, size=12, color="FFFFFF")
            header_fill = PatternFill(start_color="0066CC", end_color="0066CC", fill_type="solid")
            header_alignment = Alignment(horizontal="center", vertical="center", wrap_text=True)
            
            thin_border = Border(
                left=Side(style='thin'), right=Side(style='thin'),
                top=Side(style='thin'), bottom=Side(style='thin')
            )
            
            # Formater l'en-t√™te
            for cell in ws[1]:
                cell.font = header_font
                cell.fill = header_fill
                cell.alignment = header_alignment
                cell.border = thin_border
            
            # Largeurs optimis√©es pour causes multiples
            column_widths = {
                'A': 20, 'B': 20, 'C': 25, 'D': 30, 'E': 25, 'F': 30,
                'G': 5, 'H': 5, 'I': 5, 'J': 5, 'K': 50
            }
            
            for i, col in enumerate(self.amdec_df.columns):
                col_letter = chr(ord('A') + i)
                if col_letter in column_widths:
                    ws.column_dimensions[col_letter].width = column_widths[col_letter]
            
            # Formatage conditionnel criticit√© + bordures
            for row in range(2, len(self.amdec_df) + 2):
                criticality_col = chr(ord('A') + list(self.amdec_df.columns).index('C'))
                criticality_cell = ws[f'{criticality_col}{row}']
                criticality_value = criticality_cell.value
                
                if criticality_value is not None:
                    color = get_criticality_color(criticality_value)
                    criticality_cell.fill = PatternFill(
                        start_color=color[1:], end_color=color[1:], fill_type="solid"
                    )
                
                for col in range(1, len(self.amdec_df.columns) + 1):
                    cell = ws.cell(row=row, column=col)
                    cell.border = thin_border
                    cell.alignment = Alignment(wrap_text=True, vertical="center")
            
            wb.save(output_path)
            logger.info(f"‚úÖ Excel format√© sauvegard√©: {output_path}")
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Erreur formatage Excel: {e}")
    
    def _load_reference_models(self) -> Dict:
        """Charge les mod√®les AMDEC de r√©f√©rence"""
        models = {}
        models_dir = 'data/models'
        
        if not os.path.exists(models_dir):
            logger.warning(f"R√©pertoire mod√®les non trouv√©: {models_dir}")
            return {}
        
        for filename in os.listdir(models_dir):
            if filename.endswith('.xlsx'):
                try:
                    filepath = os.path.join(models_dir, filename)
                    df = pd.read_excel(filepath)
                    component_name = filename.replace('amdec_', '').replace('.xlsx', '')
                    models[component_name] = df
                    logger.info(f"Mod√®le charg√©: {component_name}")
                except Exception as e:
                    logger.warning(f"Erreur chargement mod√®le {filename}: {e}")
        
        return models
    
    def _build_knowledge_base(self) -> Dict:
        """Construit la base de connaissances"""
        return {
            'failure_modes': {
                'corrosion': {
                    'epingle': 'Corrosion externe',
                    'collecteur': 'Corrosion interne',
                    'tube': 'Corrosion c√¥t√© feu',
                    'branches': 'Corrosion sous contrainte'
                },
                'fissure': {
                    'epingle': 'Fissuration thermique',
                    'collecteur': 'Fissures intergranulaires',
                    'tube': 'Fatigue thermique',
                    'branches': 'Fissuration par contrainte'
                }
            },
            'corrective_actions': {
                'corrosion': [
                    'Rev√™tement c√©ramique',
                    'Contr√¥le chimie eau',
                    'Injection inhibiteurs'
                ],
                'fissure': [
                    'Inspection CND syst√©matique',
                    'R√©paration soudage',
                    'Contr√¥le contraintes'
                ]
            }
        }
    
    def _generate_from_models(self):
        """G√©n√®re AMDEC √† partir des mod√®les de r√©f√©rence"""
        logger.info("G√©n√©ration AMDEC depuis mod√®les de r√©f√©rence")
        
        for component_id, component_config in ComponentConfig.COMPONENTS.items():
            for subcomp_id, subcomp_name in component_config['subcomponents'].items():
                self._generate_typical_entries(component_id, subcomp_id)
    
    def _generate_typical_entries(self, component: str, subcomponent: str):
        """G√©n√®re des entr√©es AMDEC typiques"""
        typical_causes = ['corrosion', 'fatigue', 'erosion']
        
        for cause in typical_causes:
            frequency = 2
            gravity = 3
            detection = 2
            criticality = calculate_criticality(frequency, gravity, detection)
            
            entry = {
                'Composant': format_component_display(component),
                'Sous-composant': format_subcomponent_display(subcomponent),
                'Fonction': 'Fonction de transfert thermique',
                'Mode de D√©faillance': f'D√©faillance par {cause}',
                'Cause': cause.title(),
                'Effet': 'Impact sur performance',
                'F': frequency,
                'G': gravity,
                'D': detection,
                'C': criticality,
                'Actions Correctives': 'Maintenance pr√©ventive'
            }
            
            self.amdec_data.append(entry)
    
    def _optimize_amdec(self):
        """Optimise l'AMDEC g√©n√©r√©e"""
        if not self.amdec_data:
            return
        
        # Trier par criticit√© d√©croissante
        self.amdec_data.sort(key=lambda x: x['C'], reverse=True)
        
        logger.info(f"‚úÖ AMDEC optimis√©e: {len(self.amdec_data)} entr√©es consolid√©es")
    
    def save_to_file(self, output_path: str = None) -> str:
        """Sauvegarde l'AMDEC dans un fichier Excel"""
        if self.amdec_df is None:
            raise ValueError("Aucune AMDEC √† sauvegarder")
        
        if output_path is None:
            os.makedirs('data/generated/amdec', exist_ok=True)
            timestamp = generate_timestamp()
            filename = f"amdec_regroupee_{timestamp}.xlsx"
            output_path = os.path.join('data/generated/amdec', filename)
        
        self._save_formatted_excel_CLEAN(output_path)
        
        self.output_path = output_path
        logger.info(f"‚úÖ AMDEC regroup√©e sauvegard√©e: {output_path}")
        return output_path
    
    def get_statistics(self) -> Dict:
        """Retourne les statistiques de l'AMDEC"""
        if self.amdec_df is None or self.amdec_df.empty:
            return {}
        
        df = self.amdec_df
        stats = {
            'total_entries': len(df),
            'unique_components': df['Composant'].nunique(),
            'unique_subcomponents': df['Sous-composant'].nunique(),
            'avg_criticality': df['C'].mean(),
            'max_criticality': df['C'].max(),
            'criticality_distribution': {
                'negligeable': len(df[df['C'] <= 12]),
                'moyenne': len(df[(df['C'] > 12) & (df['C'] <= 16)]),
                'elevee': len(df[(df['C'] > 16) & (df['C'] <= 20)]),
                'critique': len(df[df['C'] > 20])
            }
        }
        
        # Ajouter les statistiques de regroupement
        stats.update(self.grouping_stats)
        
        return stats
    
    def get_grouping_report(self) -> Dict:
        """Retourne le rapport de regroupement"""
        return {
            'grouping_method': 'component_subcomponent_only',
            'causes_fusion': 'intelligent_concatenation',
            'frequency_calculation': 'official_grid_total_occurrences',
            'statistics': self.grouping_stats
        }