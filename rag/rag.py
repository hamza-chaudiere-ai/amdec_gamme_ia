#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Moteur RAG Complet pour AMDEC & Gamme IA
‚úÖ CORRIG√â: Import huggingface_hub 
ü§ñ Syst√®me de chatbot intelligent avec r√©cup√©ration augment√©e
"""

import logging
import re
import os
import json
import sqlite3
import hashlib
from typing import Dict, List, Optional, Tuple, Any
from datetime import datetime
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

import logging
logger = logging.getLogger(__name__)


# ===============================
# üîß IMPORTS AVEC GESTION D'ERREURS
# ===============================

# Imports requis avec fallbacks
try:
    import numpy as np
    NUMPY_AVAILABLE = True
except ImportError:
    NUMPY_AVAILABLE = False
    logger.warning("NumPy non disponible")

try:
    from sentence_transformers import SentenceTransformer
    SENTENCE_TRANSFORMERS_AVAILABLE = True
except ImportError:
    SENTENCE_TRANSFORMERS_AVAILABLE = False

try:
    import requests
    REQUESTS_AVAILABLE = True
except ImportError:
    REQUESTS_AVAILABLE = False

# ‚úÖ CORRECTION: Import HuggingFace Hub avec fallback
try:
    from huggingface_hub import hf_hub_download
    HUGGINGFACE_AVAILABLE = True
except ImportError:
    try:
        # Fallback pour anciennes versions
        from huggingface_hub import cached_download as hf_hub_download
        HUGGINGFACE_AVAILABLE = True
    except ImportError:
        HUGGINGFACE_AVAILABLE = False

# Imports pour traitement des documents
try:
    import docx
    from docx import Document as DocxDocument
    DOCX_AVAILABLE = True
except ImportError:
    DOCX_AVAILABLE = False

try:
    import PyPDF2
    PDF_AVAILABLE = True
except ImportError:
    PDF_AVAILABLE = False

try:
    import pandas as pd
    PANDAS_AVAILABLE = True
except ImportError:
    PANDAS_AVAILABLE = False

logger = logging.getLogger(__name__)

# ===============================
# üìö CLASSE DOCUMENT PROCESSOR
# ===============================

class DocumentProcessor:
    """Traite et extrait le contenu des documents techniques"""
    
    def __init__(self, documents_dir: str):
        self.documents_dir = documents_dir
        self.processed_docs = []
        
        # Base de connaissances par d√©faut si pas de documents
        self.default_knowledge = self._build_default_knowledge()
    
    def _build_default_knowledge(self) -> List[Dict]:
        """Construit une base de connaissances par d√©faut"""
        return [
            {
                'content': """
                CORROSION CAUSTIC ATTACK - √âCONOMISEUR BT
                
                D√©finition: La corrosion caustic attack est une forme de corrosion sp√©cifique qui affecte 
                principalement les collecteurs de sortie des √©conomiseurs basse temp√©rature. Elle se caract√©rise 
                par une attaque chimique due √† la concentration d'agents alcalins (sodium, potassium) dans l'eau.
                
                Causes principales:
                - Concentration excessive de soude caustique (NaOH)
                - Zones de stagnation avec √©vaporation
                - pH local tr√®s √©lev√© (>12)
                - Temp√©rature entre 250-350¬∞C
                
                Effets observ√©s:
                - Amincissement localis√© des parois
                - Formation de cavit√©s profondes
                - Perte de mati√®re interne importante
                - Risque de percement
                
                Solutions:
                1. Contr√¥le strict du pH de l'eau d'alimentation
                2. Limitation des concentrations en sodium (<3ppm)
                3. Am√©lioration de la circulation dans les collecteurs
                4. Surveillance par ultrasons des √©paisseurs
                5. Rev√™tement c√©ramique des zones sensibles
                
                Criticit√©: √âLEV√âE (F=3, G=5, D=3, C=45)
                Fr√©quence de contr√¥le: Mensuelle
                """,
                'source': 'Base expertise AMDEC',
                'section': 'D√©fauts √âconomiseur BT',
                'component': 'economiseur_bt',
                'defect': 'corrosion'
            },
            {
                'content': """
                SURCHAUFFE LONG TERME - SURCHAUFFEUR HT
                
                D√©finition: La surchauffe long terme (long-term overheat) est un ph√©nom√®ne de d√©gradation 
                progressive des tubes porteurs de surchauffeurs haute temp√©rature expos√©s √† des temp√©ratures 
                d√©passant leurs limites de conception sur des p√©riodes prolong√©es.
                
                M√©canisme:
                - Exposition prolong√©e √† T > 580¬∞C
                - D√©gradation de la microstructure m√©tallique
                - Formation de carbures grossiers
                - Perte de r√©sistance m√©canique
                
                Signes d'alerte:
                - D√©formation progressive des tubes (fluage)
                - Changement de couleur (oxydation)
                - Microfissures de fluage
                - Durcissement local du m√©tal
                
                Causes:
                - Mauvaise r√©partition des d√©bits de vapeur
                - Encrassement des surfaces d'√©change
                - Combustion d√©s√©quilibr√©e
                - D√©faillance du syst√®me de r√©gulation
                
                Actions correctives:
                1. Optimisation de la combustion
                2. Installation de capteurs de temp√©rature permanents
                3. Am√©lioration de la circulation vapeur
                4. Nettoyage r√©gulier des surfaces
                5. Renforcement des supports
                6. Remplacement pr√©ventif des sections critiques
                
                Criticit√©: CRITIQUE (F=2, G=5, D=2, C=20)
                """,
                'source': 'Base expertise AMDEC',
                'section': 'D√©fauts Surchauffeur HT',
                'component': 'surchauffeur_ht',
                'defect': 'surchauffe'
            },
            {
                'content': """
                ACID ATTACK - R√âCHAUFFEUR HT
                
                D√©finition: L'acid attack est une forme de corrosion acide qui affecte sp√©cifiquement 
                les branches de sortie des r√©chauffeurs haute temp√©rature. Elle r√©sulte de la condensation 
                d'acides (sulfurique, chlorhydrique) sur les surfaces m√©talliques.
                
                M√©canisme:
                - Condensation d'acides faibles (H2SO4, HCl)
                - Attaque chimique localis√©e
                - Formation de surfaces "fromage suisse"
                - Perte progressive de mati√®re
                
                Facteurs favorisants:
                - Pr√©sence de soufre dans le combustible
                - Temp√©rature de paroi < point de ros√©e acide
                - Zones de circulation r√©duite
                - Accumulation de d√©p√¥ts
                
                Pr√©vention:
                1. Maintien de la temp√©rature de paroi > 150¬∞C
                2. Am√©lioration de l'isolation thermique
                3. Optimisation des d√©bits de vapeur
                4. Nettoyage chimique p√©riodique
                5. Protection par rev√™tement r√©sistant aux acides
                6. Contr√¥le qualit√© du combustible
                
                D√©tection:
                - Inspection visuelle des surfaces
                - Mesure d'√©paisseur par ultrasons
                - Analyse chimique des d√©p√¥ts
                - Contr√¥le pH des condensats
                
                Criticit√©: √âLEV√âE (F=3, G=4, D=2, C=24)
                """,
                'source': 'Base expertise AMDEC',
                'section': 'D√©fauts R√©chauffeur HT',
                'component': 'rechauffeur_ht',
                'defect': 'corrosion'
            },
            {
                'content': """
                MAINTENANCE PR√âVENTIVE - √âCONOMISEUR BT
                
                Programme de maintenance pour √©conomiseur basse temp√©rature:
                
                INSPECTION VISUELLE (Mensuelle):
                - Contr√¥le g√©n√©ral de l'√©tat externe
                - V√©rification des supports et fixations
                - Recherche de fuites visibles
                - Documentation photographique
                Mat√©riel: Lampe torche, appareil photo, √©chelle
                Dur√©e: 45 minutes
                
                CONTR√îLE ULTRASONS (Trimestrielle):
                - Mesure d'√©paisseur des zones sensibles
                - Cartographie des amincissements
                - Suivi de l'√©volution des d√©fauts
                Mat√©riel: Appareil ultrasons, gel de contact, calibres
                Dur√©e: 90 minutes
                
                TEST D'√âTANCH√âIT√â (Semestrielle):
                - Pressurisation selon proc√©dure
                - Recherche de fuites sous pression
                - Contr√¥le des joints et brides
                Mat√©riel: Kit test √©tanch√©it√©, manom√®tres, produit traceur
                Dur√©e: 120 minutes
                
                NETTOYAGE PR√âVENTIF (Annuelle):
                - √âlimination des d√©p√¥ts internes
                - Nettoyage chimique si n√©cessaire
                - Rin√ßage et neutralisation
                Mat√©riel: Pompe circulation, produits chimiques, analyseur pH
                Dur√©e: 4-6 heures
                
                Consignes de s√©curit√©:
                - EPI obligatoires (casque, gants, lunettes)
                - Consignation √©lectrique et m√©canique
                - V√©rification absence pression/temp√©rature
                - Balisage zone intervention
                """,
                'source': 'Guide maintenance pr√©ventive',
                'section': 'Proc√©dures √âconomiseur',
                'component': 'economiseur_bt',
                'defect': 'maintenance'
            },
            {
                'content': """
                ANALYSE CRITICIT√â AMDEC - M√âTHODE F√óG√óD
                
                La criticit√© dans l'analyse AMDEC se calcule selon la formule: C = F √ó G √ó D
                
                F - FR√âQUENCE d'apparition:
                1 = Tr√®s rare (< 1 fois/10 ans)
                2 = Rare (1 fois/2-10 ans) 
                3 = Occasionnelle (1 fois/an)
                4 = Fr√©quente (plusieurs fois/an)
                5 = Tr√®s fr√©quente (> 1 fois/mois)
                
                G - GRAVIT√â des cons√©quences:
                1 = N√©gligeable (pas d'impact)
                2 = L√©g√®re (impact mineur)
                3 = Mod√©r√©e (d√©gradation performance)
                4 = Grave (arr√™t programm√©)
                5 = Catastrophique (arr√™t d'urgence, s√©curit√©)
                
                D - D√âTECTION:
                1 = D√©tection certaine (surveillance continue)
                2 = D√©tection probable (contr√¥les r√©guliers)
                3 = D√©tection possible (inspections p√©riodiques)
                4 = D√©tection improbable (pas de surveillance)
                
                NIVEAUX DE CRITICIT√â:
                C ‚â§ 12: N√©gligeable - Maintenance corrective
                12 < C ‚â§ 16: Moyenne - Maintenance pr√©ventive syst√©matique
                16 < C ‚â§ 20: √âlev√©e - Maintenance pr√©ventive conditionnelle  
                C > 20: Critique - Remise en cause conception
                
                Exemples:
                - Corrosion √©pingle √©conomiseur: F=3, G=4, D=2 ‚Üí C=24 (Critique)
                - Fissure collecteur: F=2, G=5, D=3 ‚Üí C=30 (Critique)
                - Encrassement mod√©r√©: F=4, G=2, D=1 ‚Üí C=8 (N√©gligeable)
                """,
                'source': 'M√©thode AMDEC',
                'section': 'Calcul criticit√©',
                'component': 'general',
                'defect': 'criticite'
            }
        ]
    
    def process_all_documents(self) -> List[Dict]:
        """Traite tous les documents disponibles"""
        documents = []
        
        try:
            if not os.path.exists(self.documents_dir):
                logger.warning(f"R√©pertoire documents {self.documents_dir} non trouv√©")
                return self.default_knowledge
            
            # Parcourir tous les fichiers
            for root, dirs, files in os.walk(self.documents_dir):
                for file in files:
                    file_path = os.path.join(root, file)
                    
                    if file.endswith('.docx') and DOCX_AVAILABLE:
                        docs = self._process_docx(file_path)
                        documents.extend(docs)
                    elif file.endswith('.pdf') and PDF_AVAILABLE:
                        docs = self._process_pdf(file_path)
                        documents.extend(docs)
                    elif file.endswith('.xlsx') and PANDAS_AVAILABLE:
                        docs = self._process_excel(file_path)
                        documents.extend(docs)
                    elif file.endswith(('.txt', '.md')):
                        docs = self._process_text(file_path)
                        documents.extend(docs)
            
            # Si aucun document trait√©, utiliser la base par d√©faut
            if not documents:
                logger.info("Aucun document externe trouv√©, utilisation base par d√©faut")
                return self.default_knowledge
            
            # Combiner avec la base par d√©faut
            all_documents = self.default_knowledge + documents
            
            logger.info(f"Documents trait√©s: {len(documents)} externes + {len(self.default_knowledge)} par d√©faut")
            return all_documents
            
        except Exception as e:
            logger.error(f"Erreur traitement documents: {e}")
            return self.default_knowledge
    
    def _process_docx(self, file_path: str) -> List[Dict]:
        """Traite un fichier Word"""
        try:
            doc = DocxDocument(file_path)
            filename = os.path.basename(file_path)
            
            documents = []
            current_section = "Introduction"
            content_buffer = []
            
            for paragraph in doc.paragraphs:
                text = paragraph.text.strip()
                
                if not text:
                    continue
                
                # D√©tecter les nouveaux sections (headers)
                if (paragraph.style.name.startswith('Heading') or 
                    len(text) < 100 and text.isupper()):
                    
                    # Sauvegarder la section pr√©c√©dente
                    if content_buffer:
                        documents.append({
                            'content': '\n'.join(content_buffer),
                            'source': filename,
                            'section': current_section,
                            'component': self._detect_component(current_section),
                            'defect': self._detect_defect('\n'.join(content_buffer))
                        })
                        content_buffer = []
                    
                    current_section = text
                else:
                    content_buffer.append(text)
            
            # Derni√®re section
            if content_buffer:
                documents.append({
                    'content': '\n'.join(content_buffer),
                    'source': filename,
                    'section': current_section,
                    'component': self._detect_component(current_section),
                    'defect': self._detect_defect('\n'.join(content_buffer))
                })
            
            return documents
            
        except Exception as e:
            logger.error(f"Erreur traitement DOCX {file_path}: {e}")
            return []
    
    def _process_pdf(self, file_path: str) -> List[Dict]:
        """Traite un fichier PDF"""
        try:
            with open(file_path, 'rb') as file:
                reader = PyPDF2.PdfReader(file)
                content = ""
                
                for page in reader.pages:
                    content += page.extract_text() + "\n"
            
            if content.strip():
                return [{
                    'content': content,
                    'source': os.path.basename(file_path),
                    'section': 'Document PDF',
                    'component': self._detect_component(content),
                    'defect': self._detect_defect(content)
                }]
            
            return []
            
        except Exception as e:
            logger.error(f"Erreur traitement PDF {file_path}: {e}")
            return []
    
    def _process_excel(self, file_path: str) -> List[Dict]:
        """Traite un fichier Excel"""
        try:
            df = pd.read_excel(file_path)
            filename = os.path.basename(file_path)
            documents = []
            
            # Traiter chaque ligne comme un document
            for index, row in df.iterrows():
                content_parts = []
                for col, value in row.items():
                    if pd.notna(value) and str(value).strip():
                        content_parts.append(f"{col}: {value}")
                
                if content_parts:
                    content = '\n'.join(content_parts)
                    documents.append({
                        'content': content,
                        'source': filename,
                        'section': f'Ligne {index + 1}',
                        'component': self._detect_component(content),
                        'defect': self._detect_defect(content)
                    })
            
            return documents
            
        except Exception as e:
            logger.error(f"Erreur traitement Excel {file_path}: {e}")
            return []
    
    def _process_text(self, file_path: str) -> List[Dict]:
        """Traite un fichier texte"""
        try:
            with open(file_path, 'r', encoding='utf-8') as file:
                content = file.read()
            
            if content.strip():
                return [{
                    'content': content,
                    'source': os.path.basename(file_path),
                    'section': 'Document texte',
                    'component': self._detect_component(content),
                    'defect': self._detect_defect(content)
                }]
            
            return []
            
        except Exception as e:
            logger.error(f"Erreur traitement texte {file_path}: {e}")
            return []
    
    def _detect_component(self, text: str) -> str:
        """D√©tecte le composant dans le texte"""
        text_lower = text.lower()
        
        components = {
            'economiseur_bt': ['√©conomiseur bt', 'economiseur basse', 'eco bt'],
            'economiseur_ht': ['√©conomiseur ht', 'economiseur haute', 'eco ht'],
            'surchauffeur_bt': ['surchauffeur bt', 'surchauffeur basse'],
            'surchauffeur_ht': ['surchauffeur ht', 'surchauffeur haute'],
            'rechauffeur_bt': ['r√©chauffeur bt', 'rechauffeur basse'],
            'rechauffeur_ht': ['r√©chauffeur ht', 'rechauffeur haute']
        }
        
        for component, patterns in components.items():
            for pattern in patterns:
                if pattern in text_lower:
                    return component
        
        return 'general'
    
    def _detect_defect(self, text: str) -> str:
        """D√©tecte le type de d√©faut dans le texte"""
        text_lower = text.lower()
        
        defects = {
            'corrosion': ['corrosion', 'caustic attack', 'acid attack', 'rouille'],
            'surchauffe': ['surchauffe', 'overheat', 'temp√©rature', 'fluage'],
            'fissure': ['fissure', 'crack', 'fente', 'rupture'],
            'erosion': ['√©rosion', 'usure', 'abrasion'],
            'maintenance': ['maintenance', 'inspection', 'contr√¥le'],
            'criticite': ['criticit√©', 'amdec', 'f√óg√ód']
        }
        
        for defect, patterns in defects.items():
            for pattern in patterns:
                if pattern in text_lower:
                    return defect
        
        return 'general'

# ===============================
# üóÑÔ∏è CLASSE VECTOR STORE
# ===============================

class VectorStore:
    """Stockage et recherche vectorielle avec SQLite"""
    
    def __init__(self, db_path: str):
        self.db_path = db_path
        self.embeddings_model = None
        self._init_database()
        self._init_embeddings()
    
    def _init_database(self):
        """Initialise la base de donn√©es SQLite"""
        try:
            os.makedirs(os.path.dirname(self.db_path), exist_ok=True)
            
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # Table pour les documents
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS documents (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    content TEXT NOT NULL,
                    source TEXT NOT NULL,
                    section TEXT NOT NULL,
                    component TEXT,
                    defect TEXT,
                    embedding BLOB,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            """)
            
            # Index pour recherche rapide
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_source ON documents(source)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_component ON documents(component)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_defect ON documents(defect)")
            
            conn.commit()
            conn.close()
            
        except Exception as e:
            logger.error(f"Erreur initialisation base: {e}")
    
    def _init_embeddings(self):
        """Initialise le mod√®le d'embeddings"""
        if not SENTENCE_TRANSFORMERS_AVAILABLE:
            logger.warning("SentenceTransformers non disponible, utilisation fallback")
            return
        
        try:
            # Utiliser un mod√®le multilingue optimis√©
            model_name = "all-MiniLM-L6-v2"  # Mod√®le l√©ger et performant
            self.embeddings_model = SentenceTransformer(model_name)
            logger.info(f"Mod√®le embeddings charg√©: {model_name}")
            
        except Exception as e:
            logger.error(f"Erreur chargement mod√®le embeddings: {e}")
            self.embeddings_model = None
    
    def add_documents(self, documents: List[Dict]) -> bool:
        """Ajoute des documents √† la base vectorielle"""
        try:
            if not self.embeddings_model:
                logger.warning("Mod√®le embeddings non disponible")
                return False
            
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            for doc in documents:
                content = doc['content']
                
                # G√©n√©rer l'embedding
                try:
                    embedding = self.embeddings_model.encode(content)
                    embedding_blob = embedding.tobytes()
                except Exception as e:
                    logger.warning(f"Erreur embedding document: {e}")
                    continue
                
                # Ins√©rer en base
                cursor.execute("""
                    INSERT INTO documents (content, source, section, component, defect, embedding)
                    VALUES (?, ?, ?, ?, ?, ?)
                """, (
                    content,
                    doc.get('source', 'Unknown'),
                    doc.get('section', 'Unknown'),
                    doc.get('component', 'general'),
                    doc.get('defect', 'general'),
                    embedding_blob
                ))
            
            conn.commit()
            conn.close()
            
            logger.info(f"Ajout√© {len(documents)} documents √† la base vectorielle")
            return True
            
        except Exception as e:
            logger.error(f"Erreur ajout documents: {e}")
            return False
    
    def search(self, query: str, n_results: int = 5, min_similarity: float = 0.1) -> List[Dict]:
        """Recherche s√©mantique dans la base"""
        try:
            if not self.embeddings_model:
                return self._fallback_search(query, n_results)
            
            # Encoder la requ√™te
            query_embedding = self.embeddings_model.encode(query)
            
            # R√©cup√©rer tous les documents
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute("""
                SELECT id, content, source, section, component, defect, embedding
                FROM documents
            """)
            
            results = []
            for row in cursor.fetchall():
                doc_id, content, source, section, component, defect, embedding_blob = row
                
                if embedding_blob:
                    # Reconstituer l'embedding
                    doc_embedding = np.frombuffer(embedding_blob, dtype=np.float32)
                    
                    # Calculer la similarit√© cosinus
                    similarity = self._cosine_similarity(query_embedding, doc_embedding)
                    
                    if similarity >= min_similarity:
                        results.append({
                            'id': doc_id,
                            'content': content,
                            'source': source,
                            'section': section,
                            'component': component,
                            'defect': defect,
                            'similarity': float(similarity)
                        })
            
            conn.close()
            
            # Trier par similarit√©
            results.sort(key=lambda x: x['similarity'], reverse=True)
            
            return results[:n_results]
            
        except Exception as e:
            logger.error(f"Erreur recherche: {e}")
            return self._fallback_search(query, n_results)
    
    def search_by_keywords(self, keywords: List[str], n_results: int = 3) -> List[Dict]:
        """Recherche par mots-cl√©s (fallback)"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # Construire la requ√™te LIKE
            like_conditions = []
            params = []
            
            for keyword in keywords:
                like_conditions.append("content LIKE ?")
                params.append(f"%{keyword}%")
            
            query = f"""
                SELECT content, source, section, component, defect
                FROM documents
                WHERE {' OR '.join(like_conditions)}
                LIMIT ?
            """
            params.append(n_results)
            
            cursor.execute(query, params)
            
            results = []
            for row in cursor.fetchall():
                content, source, section, component, defect = row
                results.append({
                    'content': content,
                    'source': source,
                    'section': section,
                    'component': component,
                    'defect': defect,
                    'similarity': 0.5  # Similarit√© par d√©faut pour mots-cl√©s
                })
            
            conn.close()
            return results
            
        except Exception as e:
            logger.error(f"Erreur recherche mots-cl√©s: {e}")
            return []
    
    def _fallback_search(self, query: str, n_results: int) -> List[Dict]:
        """Recherche de fallback bas√©e sur mots-cl√©s"""
        query_words = query.lower().split()
        return self.search_by_keywords(query_words, n_results)
    
    def _cosine_similarity(self, a: np.ndarray, b: np.ndarray) -> float:
        """Calcule la similarit√© cosinus entre deux vecteurs"""
        if not NUMPY_AVAILABLE:
            return 0.5
        
        try:
            dot_product = np.dot(a, b)
            norm_a = np.linalg.norm(a)
            norm_b = np.linalg.norm(b)
            
            if norm_a == 0 or norm_b == 0:
                return 0.0
            
            return dot_product / (norm_a * norm_b)
            
        except Exception:
            return 0.5
    
    def clear_collection(self):
        """Vide la collection de documents"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            cursor.execute("DELETE FROM documents")
            conn.commit()
            conn.close()
            logger.info("Collection vid√©e")
        except Exception as e:
            logger.error(f"Erreur vidage collection: {e}")
    
    def get_collection_stats(self) -> Dict:
        """Retourne les statistiques de la collection"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute("SELECT COUNT(*) FROM documents")
            total_docs = cursor.fetchone()[0]
            
            cursor.execute("SELECT DISTINCT source FROM documents LIMIT 10")
            sample_sources = [row[0] for row in cursor.fetchall()]
            
            conn.close()
            
            return {
                'total_documents': total_docs,
                'sample_sources': sample_sources
            }
            
        except Exception as e:
            logger.error(f"Erreur stats collection: {e}")
            return {'total_documents': 0, 'sample_sources': []}
    
    def is_healthy(self) -> bool:
        """V√©rifie la sant√© de la base vectorielle"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            cursor.execute("SELECT COUNT(*) FROM documents")
            count = cursor.fetchone()[0]
            conn.close()
            return count > 0
        except Exception:
            return False

# ===============================
# ü§ñ CLASSE LLM CLIENT  
# ===============================

class LLMClient:
    """Client pour interaction avec LLM (Groq/OpenAI compatible)"""
    
    def __init__(self, config_path: str):
        self.config_path = config_path
        self.config = {}
        self._load_config()
    
    def _load_config(self):
        """Charge la configuration LLM"""
        try:
            if os.path.exists(self.config_path):
                with open(self.config_path, 'r') as f:
                    self.config = json.load(f)
            else:
                # Configuration par d√©faut
                self.config = {
                    "type": "api",
                    "name": "llama3-70b-8192",
                    "api_key": "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",
                    "api_url": "https://api.groq.com/openai/v1/chat/completions"
                }
                
                # Sauvegarder la config par d√©faut
                with open(self.config_path, 'w') as f:
                    json.dump(self.config, f, indent=2)
                
                logger.info("Configuration LLM par d√©faut cr√©√©e")
            
        except Exception as e:
            logger.error(f"Erreur chargement config LLM: {e}")
            self.config = {}
    
    def test_connection(self) -> bool:
        """Teste la connexion au LLM"""
        if not REQUESTS_AVAILABLE:
            logger.warning("Requests non disponible pour test LLM")
            return False
        
        try:
            if not self.config.get('api_key') or not self.config.get('api_url'):
                return False
            
            headers = {
                'Authorization': f"Bearer {self.config['api_key']}",
                'Content-Type': 'application/json'
            }
            
            data = {
                'model': self.config.get('name', 'llama3-70b-8192'),
                'messages': [{'role': 'user', 'content': 'Test'}],
                'max_tokens': 10,
                'temperature': 0.1
            }
            
            response = requests.post(
                self.config['api_url'],
                headers=headers,
                json=data,
                timeout=10
            )
            
            return response.status_code == 200
            
        except Exception as e:
            logger.warning(f"Test connexion LLM √©chou√©: {e}")
            return False
    
    def generate_response(self, system_prompt: str, user_query: str, 
                         context: str, temperature: float = 0.7) -> str:
        """G√©n√®re une r√©ponse via le LLM"""
        if not REQUESTS_AVAILABLE:
            return self._fallback_response(user_query, context)
        
        try:
            headers = {
                'Authorization': f"Bearer {self.config['api_key']}",
                'Content-Type': 'application/json'
            }
            
            # Construire le prompt complet
            full_prompt = f"""Contexte technique:
{context}

Question: {user_query}

R√©ponds de mani√®re pr√©cise et technique en te basant sur le contexte fourni."""
            
            data = {
                'model': self.config.get('name', 'llama3-70b-8192'),
                'messages': [
                    {'role': 'system', 'content': system_prompt},
                    {'role': 'user', 'content': full_prompt}
                ],
                'max_tokens': 1000,
                'temperature': temperature
            }
            
            response = requests.post(
                self.config['api_url'],
                headers=headers,
                json=data,
                timeout=30
            )
            
            if response.status_code == 200:
                result = response.json()
                return result['choices'][0]['message']['content']
            else:
                logger.error(f"Erreur API LLM: {response.status_code}")
                return self._fallback_response(user_query, context)
                
        except Exception as e:
            logger.error(f"Erreur g√©n√©ration r√©ponse LLM: {e}")
            return self._fallback_response(user_query, context)
    
    def _fallback_response(self, user_query: str, context: str) -> str:
        """R√©ponse de fallback bas√©e sur le contexte"""
        query_lower = user_query.lower()
        
        # R√©ponses pr√©d√©finies selon le type de question
        if 'caustic attack' in query_lower:
            return """La corrosion caustic attack est une forme de corrosion sp√©cifique aux √©conomiseurs BT.
            
**Causes**: Concentration excessive de soude caustique (NaOH), zones de stagnation.
**Solutions**: Contr√¥le pH, limitation sodium <3ppm, surveillance ultrasons.
**Criticit√©**: √âLEV√âE (C=45)"""
        
        elif 'surchauffe' in query_lower and 'long terme' in query_lower:
            return """La surchauffe long terme affecte les surchauffeurs HT expos√©s √† T>580¬∞C.
            
**Effets**: Fluage, d√©formation, perte r√©sistance m√©canique.
**Solutions**: Optimisation combustion, capteurs temp√©rature, renforcement supports.
**Criticit√©**: CRITIQUE (C=20)"""
        
        elif 'acid attack' in query_lower:
            return """L'acid attack touche les r√©chauffeurs HT par condensation d'acides.
            
**Pr√©vention**: Maintien T>150¬∞C, am√©lioration isolation, nettoyage chimique.
**D√©tection**: Inspection visuelle, mesure ultrasons.
**Criticit√©**: √âLEV√âE (C=24)"""
        
        elif any(word in query_lower for word in ['maintenance', 'contr√¥le', 'inspection']):
            return """Programme de maintenance pr√©ventive recommand√©:
            
- **Mensuel**: Inspection visuelle (45 min)
- **Trimestriel**: Contr√¥le ultrasons (90 min)  
- **Semestriel**: Test √©tanch√©it√© (120 min)
- **Annuel**: Nettoyage complet (4-6h)

**S√©curit√©**: EPI, consignation, v√©rification pression/temp√©rature."""
        
        elif 'criticit√©' in query_lower or 'amdec' in query_lower:
            return """Calcul criticit√© AMDEC: C = F √ó G √ó D
            
**Niveaux**:
- C ‚â§ 12: N√©gligeable (maintenance corrective)
- 12 < C ‚â§ 16: Moyenne (pr√©ventive syst√©matique)
- 16 < C ‚â§ 20: √âlev√©e (pr√©ventive conditionnelle)
- C > 20: Critique (remise en cause conception)

**F**: Fr√©quence (1-5), **G**: Gravit√© (1-5), **D**: D√©tection (1-4)"""
        
        else:
            # Extraire des informations du contexte si disponible
            if context and len(context) > 100:
                # Prendre les premiers 300 caract√®res du contexte
                summary = context[:300] + "..."
                return f"""Bas√© sur la documentation technique disponible:

{summary}

Pour une r√©ponse plus pr√©cise, veuillez reformuler votre question ou pr√©ciser le composant concern√©."""
            
            return """Je peux vous aider avec les questions concernant:
            
üîß **Composants**: √âconomiseurs, Surchauffeurs, R√©chauffeurs (BT/HT)
‚ö†Ô∏è **D√©fauts**: Corrosion, Surchauffe, Fissures, √ârosion
üõ†Ô∏è **Maintenance**: Proc√©dures, Fr√©quences, Mat√©riel
üìä **AMDEC**: Calculs criticit√©, Analyses F√óG√óD

Exemple: "J'ai un percement sur l'√©conomiseur BT, que faire ?" """
    
    def get_system_prompt(self) -> str:
        """Retourne le prompt syst√®me pour le chatbot"""
        return """Tu es un expert en maintenance industrielle sp√©cialis√© dans les chaudi√®res et l'analyse AMDEC.

**Ton r√¥le**: Fournir des conseils techniques pr√©cis sur la maintenance des √©quipements de chaudi√®re.

**Expertise**: 
- Analyses AMDEC et calculs de criticit√© (F√óG√óD)
- D√©fauts courants: corrosion, surchauffe, fissures, √©rosion
- Composants: √âconomiseurs, Surchauffeurs, R√©chauffeurs (BT/HT)
- Maintenance pr√©ventive et corrective

**Style de r√©ponse**:
- Pr√©cis et technique mais accessible
- Structure claire avec sections (Diagnostic, Solutions, Pr√©vention)
- Indications de criticit√© et urgence
- Consignes de s√©curit√© importantes

**Utilise le contexte fourni** pour donner des r√©ponses pr√©cises bas√©es sur la documentation technique."""
    
    def get_available_models(self) -> List[str]:
        """Retourne la liste des mod√®les disponibles"""
        return [
            "llama3-70b-8192",
            "llama3-8b-8192",
            "mixtral-8x7b-32768",
            "gemma-7b-it"
        ]

# ===============================
# ü§ñ CLASSE RAG ENGINE PRINCIPALE
# ===============================

class RAGEngine:
    """Moteur RAG principal orchestrant la recherche et g√©n√©ration de r√©ponses"""
    
    def __init__(self, 
                 documents_dir: str = "data/documents",
                 vector_db_path: str = "data/vector_db/chroma.db",
                 llm_config_path: str = "llm_config.json"):
        """
        Initialise le moteur RAG
        
        Args:
            documents_dir: R√©pertoire des documents techniques
            vector_db_path: Chemin de la base vectorielle
            llm_config_path: Configuration du LLM
        """
        self.documents_dir = documents_dir
        self.vector_db_path = vector_db_path
        self.llm_config_path = llm_config_path
        
        # Initialiser les composants
        self.document_processor = DocumentProcessor(documents_dir)
        self.vector_store = VectorStore(vector_db_path)
        self.llm_client = LLMClient(llm_config_path)
        
        # √âtat d'initialisation
        self.is_initialized = False
        self.last_index_update = None
        
        # Patterns de d√©tection pour am√©liorer la recherche
        self.component_patterns = {
            'economiseur_bt': ['√©conomiseur bt', 'economiseur basse temp√©rature', 'eco bt'],
            'economiseur_ht': ['√©conomiseur ht', 'economiseur haute temp√©rature', 'eco ht'],
            'surchauffeur_bt': ['surchauffeur bt', 'surchauffeur basse temp√©rature', 'sur bt'],
            'surchauffeur_ht': ['surchauffeur ht', 'surchauffeur haute temp√©rature', 'sur ht'],
            'rechauffeur_bt': ['r√©chauffeur bt', 'rechauffeur basse temp√©rature', 'rch bt'],
            'rechauffeur_ht': ['r√©chauffeur ht', 'rechauffeur haute temp√©rature', 'rch ht']
        }
        
        self.defect_patterns = {
            'corrosion': ['corrosion', 'rouille', 'oxydation', 'attaque', 'caustic', 'acid'],
            'fissure': ['fissure', 'crack', 'fente', 'cassure', 'rupture'],
            'percement': ['percement', 'trou', 'perforation', 'perce'],
            'surchauffe': ['surchauffe', 'temp√©rature', 'overheat', 'thermique', 'fluage'],
            'erosion': ['√©rosion', 'usure', 'abrasion', 'd√©gradation'],
            'fatigue': ['fatigue', 'cycles', 'contrainte', 'stress']
        }
    
    def initialize(self, force_reindex: bool = False) -> bool:
        """
        Initialise le moteur RAG et indexe les documents
        
        Args:
            force_reindex: Force la r√©indexation des documents
            
        Returns:
            True si l'initialisation r√©ussit
        """
        try:
            logger.info("üöÄ Initialisation du moteur RAG...")
            
            # V√©rifier la sant√© des composants
            llm_healthy = self.llm_client.test_connection()
            if not llm_healthy:
                logger.warning("‚ö†Ô∏è Connexion LLM non optimale, mais RAG fonctionnel")
            
            if not self.vector_store.is_healthy():
                logger.info("üîÑ Initialisation de la base vectorielle...")
                self.vector_store.clear_collection()
            
            # V√©rifier si indexation n√©cessaire
            stats = self.vector_store.get_collection_stats()
            needs_indexing = (
                force_reindex or 
                stats.get('total_documents', 0) == 0 or
                self._should_reindex()
            )
            
            if needs_indexing:
                logger.info("üìö Indexation des documents n√©cessaire...")
                if not self._index_documents():
                    logger.warning("‚ö†Ô∏è √âchec de l'indexation, utilisation base par d√©faut")
            else:
                logger.info(f"‚úÖ Base vectorielle OK ({stats.get('total_documents', 0)} documents)")
            
            self.is_initialized = True
            self.last_index_update = datetime.now()
            
            logger.info("‚úÖ Moteur RAG initialis√© avec succ√®s")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Erreur initialisation RAG: {e}")
            # M√™me en cas d'erreur, marquer comme initialis√© pour fallback
            self.is_initialized = True
            return True  # Retourner True pour permettre le fonctionnement en mode d√©grad√©
    
    def _should_reindex(self) -> bool:
        """D√©termine si une r√©indexation est n√©cessaire"""
        try:
            # V√©rifier la pr√©sence de nouveaux documents
            if not os.path.exists(self.documents_dir):
                return True
            
            doc_files = []
            for root, dirs, files in os.walk(self.documents_dir):
                for file in files:
                    if any(file.endswith(ext) for ext in ['.docx', '.pdf', '.xlsx', '.md', '.txt']):
                        doc_files.append(os.path.join(root, file))
            
            # Si plus de 0 fichiers documents et moins de 5 entr√©es vectorielles
            stats = self.vector_store.get_collection_stats()
            return len(doc_files) > 0 and stats.get('total_documents', 0) < 5
            
        except Exception as e:
            logger.warning(f"Erreur v√©rification r√©indexation: {e}")
            return True
    
    def _index_documents(self) -> bool:
        """Indexe tous les documents dans la base vectorielle"""
        try:
            logger.info("üîÑ Traitement et indexation des documents...")
            
            # Traiter les documents
            documents = self.document_processor.process_all_documents()
            
            if not documents:
                logger.warning("‚ö†Ô∏è Aucun document trouv√©")
                return False
            
            # Nettoyer la collection existante si n√©cessaire
            if self.vector_store.get_collection_stats().get('total_documents', 0) > 0:
                logger.info("üßπ Nettoyage de la base vectorielle existante...")
                self.vector_store.clear_collection()
            
            # Ajouter les documents
            success = self.vector_store.add_documents(documents)
            
            if success:
                stats = self.vector_store.get_collection_stats()
                logger.info(f"‚úÖ Indexation termin√©e: {stats.get('total_documents', 0)} documents")
            
            return success
            
        except Exception as e:
            logger.error(f"‚ùå Erreur indexation documents: {e}")
            return False
    
    def query(self, user_question: str, max_context_length: int = 3000) -> Dict:
        """
        Traite une question utilisateur et g√©n√®re une r√©ponse
        
        Args:
            user_question: Question de l'utilisateur
            max_context_length: Longueur maximale du contexte RAG
            
        Returns:
            Dictionnaire avec r√©ponse, contexte, m√©tadonn√©es
        """
        try:
            if not self.is_initialized:
                logger.warning("Moteur RAG non initialis√©, tentative d'initialisation...")
                if not self.initialize():
                    return {
                        'response': "D√©sol√©, le syst√®me n'est pas encore pr√™t. Veuillez r√©essayer dans quelques instants.",
                        'error': 'RAG not initialized',
                        'context': '',
                        'sources': []
                    }
            
            logger.info(f"üîç Traitement de la question: {user_question[:100]}...")
            
            # √âtape 1: Analyser la question
            analysis = self._analyze_question(user_question)
            
            # √âtape 2: Recherche vectorielle
            relevant_docs = self._search_relevant_documents(user_question, analysis)
            
            # √âtape 3: Construire le contexte
            context = self._build_context(relevant_docs, max_context_length)
            
            # √âtape 4: G√©n√©rer la r√©ponse
            response = self._generate_response(user_question, context, analysis)
            
            # √âtape 5: Post-traitement
            final_response = self._post_process_response(response, analysis)
            
            return {
                'response': final_response,
                'context': context,
                'sources': [doc.get('source', 'Unknown') for doc in relevant_docs],
                'detected_components': analysis.get('components', []),
                'detected_defects': analysis.get('defects', []),
                'confidence': self._calculate_confidence(relevant_docs),
                'timestamp': datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"‚ùå Erreur traitement question: {e}")
            return {
                'response': f"D√©sol√©, une erreur s'est produite lors du traitement de votre question. Veuillez r√©essayer ou reformuler votre demande.",
                'error': str(e),
                'context': '',
                'sources': []
            }
    
    def _analyze_question(self, question: str) -> Dict:
        """Analyse la question pour d√©tecter composants et d√©fauts"""
        analysis = {
            'components': [],
            'defects': [],
            'question_type': 'general',
            'keywords': []
        }
        
        question_lower = question.lower()
        
        # D√©tecter les composants
        for component, patterns in self.component_patterns.items():
            for pattern in patterns:
                if pattern in question_lower:
                    if component not in analysis['components']:
                        analysis['components'].append(component)
                    analysis['keywords'].append(pattern)
                    break
        
        # D√©tecter les d√©fauts
        for defect, patterns in self.defect_patterns.items():
            for pattern in patterns:
                if pattern in question_lower:
                    if defect not in analysis['defects']:
                        analysis['defects'].append(defect)
                    analysis['keywords'].append(pattern)
                    break
        
        # D√©terminer le type de question
        if any(word in question_lower for word in ['que faire', 'solution', 'r√©parer', 'corriger']):
            analysis['question_type'] = 'solution'
        elif any(word in question_lower for word in ['qu\'est-ce', 'd√©finition', 'expliquer']):
            analysis['question_type'] = 'explanation'
        elif any(word in question_lower for word in ['criticit√©', 'urgent', 'priorit√©']):
            analysis['question_type'] = 'criticality'
        elif any(word in question_lower for word in ['maintenance', 'contr√¥le', 'inspection']):
            analysis['question_type'] = 'maintenance'
        
        return analysis
    
    def _search_relevant_documents(self, question: str, analysis: Dict) -> List[Dict]:
        """Recherche les documents pertinents"""
        # Recherche s√©mantique principale
        semantic_results = self.vector_store.search(question, n_results=5, min_similarity=0.1)
        
        # Recherche par mots-cl√©s sp√©cifiques
        keywords = analysis.get('keywords', [])
        if keywords:
            keyword_results = self.vector_store.search_by_keywords(keywords, n_results=3)
        else:
            keyword_results = []
        
        # Combiner et d√©duplicater
        all_results = semantic_results + keyword_results
        
        # D√©duplication par contenu
        seen_content = set()
        unique_results = []
        
        for doc in all_results:
            content_preview = doc.get('content', '')[:200]  # Premiers 200 caract√®res
            content_hash = hash(content_preview)
            if content_hash not in seen_content:
                seen_content.add(content_hash)
                unique_results.append(doc)
        
        # Trier par pertinence (similarit√© + bonus pour mots-cl√©s)
        for doc in unique_results:
            bonus = 0
            if keywords:
                content_lower = doc.get('content', '').lower()
                for keyword in keywords:
                    if keyword.lower() in content_lower:
                        bonus += 0.1
            doc['final_score'] = doc.get('similarity', 0.5) + bonus
        
        # Trier et limiter
        sorted_results = sorted(unique_results, key=lambda x: x.get('final_score', 0), reverse=True)
        
        return sorted_results[:6]  # Limiter √† 6 documents maximum
    
    def _build_context(self, documents: List[Dict], max_length: int) -> str:
        """Construit le contexte RAG √† partir des documents pertinents"""
        if not documents:
            return ""
        
        context_parts = []
        current_length = 0
        
        for i, doc in enumerate(documents):
            content = doc.get('content', '')
            source = doc.get('source', 'Unknown')
            section = doc.get('section', 'Unknown')
            
            # Formater l'extrait
            formatted_doc = f"[Source: {source} - {section}]\n{content}\n"
            
            # V√©rifier la longueur
            if current_length + len(formatted_doc) > max_length:
                if current_length == 0:  # Au moins inclure le premier document
                    # Tronquer le document
                    available_space = max_length - len(f"[Source: {source} - {section}]\n") - 50
                    if available_space > 100:
                        truncated_content = content[:available_space] + "..."
                        formatted_doc = f"[Source: {source} - {section}]\n{truncated_content}\n"
                        context_parts.append(formatted_doc)
                break
            
            context_parts.append(formatted_doc)
            current_length += len(formatted_doc)
        
        return "\n".join(context_parts)
    
    def _generate_response(self, question: str, context: str, analysis: Dict) -> str:
        """G√©n√®re la r√©ponse via le LLM"""
        # Construire un prompt syst√®me adapt√© au type de question
        system_prompt = self.llm_client.get_system_prompt()
        
        # Ajouter des instructions sp√©cifiques selon le type de question
        question_type = analysis.get('question_type', 'general')
        
        if question_type == 'solution':
            system_prompt += "\n\nPour cette question de r√©solution de probl√®me, structure ta r√©ponse ainsi:\n" \
                           "1. **Diagnostic** du probl√®me\n" \
                           "2. **Solutions imm√©diates** √† mettre en ≈ìuvre\n" \
                           "3. **Actions pr√©ventives** pour √©viter la r√©currence\n" \
                           "4. **Niveau de criticit√©** et urgence\n" \
                           "5. **Consignes de s√©curit√©** importantes"
        
        elif question_type == 'explanation':
            system_prompt += "\n\nPour cette question d'explication, fournis:\n" \
                           "1. **D√©finition claire** du ph√©nom√®ne\n" \
                           "2. **Causes principales** identifi√©es\n" \
                           "3. **Cons√©quences** possibles\n" \
                           "4. **Pr√©vention** recommand√©e"
        
        elif question_type == 'maintenance':
            system_prompt += "\n\nPour cette question de maintenance, indique:\n" \
                           "1. **Op√©rations** recommand√©es\n" \
                           "2. **Fr√©quence** d'intervention\n" \
                           "3. **Mat√©riel** n√©cessaire\n" \
                           "4. **Proc√©dure** d√©taill√©e\n" \
                           "5. **Points de contr√¥le** critiques"
        
        # G√©n√©rer la r√©ponse
        response = self.llm_client.generate_response(
            system_prompt=system_prompt,
            user_query=question,
            context=context,
            temperature=0.7
        )
        
        return response
    
    def _post_process_response(self, response: str, analysis: Dict) -> str:
        """Post-traite la r√©ponse pour am√©liorer la qualit√©"""
        # Ajouter des informations de contexte si pertinent
        components = analysis.get('components', [])
        defects = analysis.get('defects', [])
        
        # Ajouter une note sur les composants d√©tect√©s
        if components or defects:
            context_note = "\n\n---\n"
            
            if components:
                comp_names = {
                    'economiseur_bt': '√âconomiseur BT',
                    'economiseur_ht': '√âconomiseur HT',
                    'surchauffeur_bt': 'Surchauffeur BT',
                    'surchauffeur_ht': 'Surchauffeur HT',
                    'rechauffeur_bt': 'R√©chauffeur BT',
                    'rechauffeur_ht': 'R√©chauffeur HT'
                }
                detected_comps = [comp_names.get(comp, comp) for comp in components]
                context_note += f"üîß **Composant(s) identifi√©(s)**: {', '.join(detected_comps)}\n"
            
            if defects:
                defect_names = {
                    'corrosion': 'Corrosion',
                    'fissure': 'Fissuration',
                    'percement': 'Percement',
                    'surchauffe': 'Surchauffe',
                    'erosion': '√ârosion',
                    'fatigue': 'Fatigue'
                }
                detected_defects = [defect_names.get(defect, defect) for defect in defects]
                context_note += f"‚ö†Ô∏è **D√©faut(s) identifi√©(s)**: {', '.join(detected_defects)}\n"
            
            context_note += "\nüí° *Cette analyse est bas√©e sur la base de connaissances AMDEC & Gamme IA*"
            
            response += context_note
        
        return response
    
    def _calculate_confidence(self, documents: List[Dict]) -> float:
        """Calcule le niveau de confiance de la r√©ponse"""
        if not documents:
            return 0.3  # Confiance minimale
        
        # Confiance bas√©e sur:
        # - Nombre de documents pertinents
        # - Similarit√© moyenne
        # - Diversit√© des sources
        
        similarities = [doc.get('similarity', 0.5) for doc in documents]
        avg_similarity = sum(similarities) / len(similarities)
        
        # Bonus pour multiple documents
        doc_bonus = min(len(documents) / 5.0, 1.0)
        
        # Bonus pour diversit√© des sources
        sources = set(doc.get('source', 'unknown') for doc in documents)
        source_bonus = min(len(sources) / 3.0, 1.0)
        
        confidence = (avg_similarity + doc_bonus * 0.2 + source_bonus * 0.1)
        
        return min(round(confidence, 2), 1.0)
    
    def get_system_status(self) -> Dict:
        """Retourne l'√©tat du syst√®me RAG"""
        try:
            vector_stats = self.vector_store.get_collection_stats()
            llm_healthy = self.llm_client.test_connection()
            
            return {
                'initialized': self.is_initialized,
                'last_index_update': self.last_index_update.isoformat() if self.last_index_update else None,
                'vector_store': {
                    'healthy': self.vector_store.is_healthy(),
                    'total_documents': vector_stats.get('total_documents', 0),
                    'sample_sources': vector_stats.get('sample_sources', [])
                },
                'llm_client': {
                    'healthy': llm_healthy,
                    'model': self.llm_client.config.get('name', 'unknown'),
                    'available_models': self.llm_client.get_available_models()
                },
                'components_supported': list(self.component_patterns.keys()),
                'defects_detected': list(self.defect_patterns.keys()),
                'dependencies': {
                    'sentence_transformers': SENTENCE_TRANSFORMERS_AVAILABLE,
                    'numpy': NUMPY_AVAILABLE,
                    'requests': REQUESTS_AVAILABLE,
                    'pandas': PANDAS_AVAILABLE,
                    'docx': DOCX_AVAILABLE,
                    'pdf': PDF_AVAILABLE
                }
            }
            
        except Exception as e:
            logger.error(f"Erreur statut syst√®me: {e}")
            return {'error': str(e)}
    
    def update_knowledge_base(self) -> bool:
        """Met √† jour la base de connaissances"""
        try:
            logger.info("üîÑ Mise √† jour de la base de connaissances...")
            return self.initialize(force_reindex=True)
        except Exception as e:
            logger.error(f"Erreur mise √† jour base: {e}")
            return False